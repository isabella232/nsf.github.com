var gortfmData = {index:"index.html",html:"<p>\nPackage html implements an HTML5-compliant tokenizer and parser.\n</p>\n<p>\nTokenization is done by creating a Tokenizer for an io.Reader r. It is the\ncaller&#39;s responsibility to ensure that r provides UTF-8 encoded HTML.\n</p>\n<pre>z := html.NewTokenizer(r)\n</pre>\n<p>\nGiven a Tokenizer z, the HTML is tokenized by repeatedly calling z.Next(),\nwhich parses the next token and returns its type, or an error:\n</p>\n<pre>for {\n\ttt := z.Next()\n\tif tt == html.ErrorToken {\n\t\t// ...\n\t\treturn ...\n\t}\n\t// Process the current token.\n}\n</pre>\n<p>\nThere are two APIs for retrieving the current token. The high-level API is to\ncall Token; the low-level API is to call Text or TagName / TagAttr. Both APIs\nallow optionally calling Raw after Next but before Token, Text, TagName, or\nTagAttr. In EBNF notation, the valid call sequence per token is:\n</p>\n<pre>Next {Raw} [ Token | Text | TagName {TagAttr} ]\n</pre>\n<p>\nToken returns an independent data structure that completely describes a token.\nEntities (such as &#34;&amp;lt;&#34;) are unescaped, tag names and attribute keys are\nlower-cased, and attributes are collected into a []Attribute. For example:\n</p>\n<pre>for {\n\tif z.Next() == html.ErrorToken {\n\t\t// Returning os.EOF indicates success.\n\t\treturn z.Error()\n\t}\n\temitToken(z.Token())\n}\n</pre>\n<p>\nThe low-level API performs fewer allocations and copies, but the contents of\nthe []byte values returned by Text, TagName and TagAttr may change on the next\ncall to Next. For example, to extract an HTML page&#39;s anchor text:\n</p>\n<pre>depth := 0\nfor {\n\ttt := z.Next()\n\tswitch tt {\n\tcase ErrorToken:\n\t\treturn z.Error()\n\tcase TextToken:\n\t\tif depth &gt; 0 {\n\t\t\t// emitBytes should copy the []byte it receives,\n\t\t\t// if it doesn&#39;t process it immediately.\n\t\t\temitBytes(z.Text())\n\t\t}\n\tcase StartTagToken, EndTagToken:\n\t\ttn, _ := z.TagName()\n\t\tif len(tn) == 1 &amp;&amp; tn[0] == &#39;a&#39; {\n\t\t\tif tt == StartTag {\n\t\t\t\tdepth++\n\t\t\t} else {\n\t\t\t\tdepth--\n\t\t\t}\n\t\t}\n\t}\n}\n</pre>\n<p>\nA Tokenizer typically skips over HTML comments. To return comment tokens, set\nTokenizer.ReturnComments to true before looping over calls to Next.\n</p>\n<p>\nParsing is done by calling Parse with an io.Reader, which returns the root of\nthe parse tree (the document element) as a *Node. It is the caller&#39;s\nresponsibility to ensure that the Reader provides UTF-8 encoded HTML. For\nexample, to process each anchor node in depth-first order:\n</p>\n<pre>doc, err := html.Parse(r)\nif err != nil {\n\t// ...\n}\nvar f func(*html.Node)\nf = func(n *html.Node) {\n\tif n.Type == html.ElementNode &amp;&amp; n.Data == &#34;a&#34; {\n\t\t// Do something with n...\n\t}\n\tfor _, c := range n.Child {\n\t\tf(c)\n\t}\n}\nf(doc)\n</pre>\n<p>\nThe relevant specifications include:\n<a href=\"http://www.whatwg.org/specs/web-apps/current-work/multipage/syntax.html\">http://www.whatwg.org/specs/web-apps/current-work/multipage/syntax.html</a> and\n<a href=\"http://www.whatwg.org/specs/web-apps/current-work/multipage/tokenization.html\">http://www.whatwg.org/specs/web-apps/current-work/multipage/tokenization.html</a>\n</p>\n",name:"html",types:[{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:Attribute!\">Attribute</a></h2>\n<pre>type Attribute struct {\n\tKey, Val string\n}</pre>\n<p>\nAn Attribute is an attribute key-value pair. Key is alphabetic (and hence\ndoes not contain escapable characters like &#39;&amp;&#39;, &#39;&lt;&#39; or &#39;&gt;&#39;), and Val is\nunescaped (it looks like &#34;a&lt;b&#34; rather than &#34;a&amp;lt;b&#34;).\n</p>\n\n",name:"Attribute","methods":[]},{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:Node!\">Node</a></h2>\n<pre>type Node struct {\n\tParent *Node\n\tChild  []*Node\n\tType   NodeType\n\tData   string\n\tAttr   []Attribute\n}</pre>\n<p>\nA Node consists of a NodeType and some Data (tag name for element nodes,\ncontent for text) and are part of a tree of Nodes. Element nodes may also\ncontain a slice of Attributes. Data is unescaped, so that it looks like\n&#34;a&lt;b&#34; rather than &#34;a&amp;lt;b&#34;.\n</p>\n\n",name:"Node","methods":[]},{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:NodeType!\">NodeType</a></h2>\n<pre>type NodeType int</pre>\n<p>\nA NodeType is the type of a Node.\n</p>\n\n",name:"NodeType","methods":[]},{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:Token!\">Token</a></h2>\n<pre>type Token struct {\n\tType TokenType\n\tData string\n\tAttr []Attribute\n}</pre>\n<p>\nA Token consists of a TokenType and some Data (tag name for start and end\ntags, content for text and comments). A tag Token may also contain a slice\nof Attributes. Data is unescaped for all Tokens (it looks like &#34;a&lt;b&#34; rather\nthan &#34;a&amp;lt;b&#34;).\n</p>\n\n",name:"Token","methods":[{html:"\n<h2><a class=\"black\" href=\"?m:Token\">func (Token)</a> <a href=\"?m:Token.String!\">String</a></h2>\n<code>func (t Token) String() string</code>\n<p>\nString returns a string representation of the Token.\n</p>\n\n",name:"String"}]},{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:TokenType!\">TokenType</a></h2>\n<pre>type TokenType int</pre>\n<p>\nA TokenType is the type of a Token.\n</p>\n\n",name:"TokenType","methods":[{html:"\n<h2><a class=\"black\" href=\"?m:TokenType\">func (TokenType)</a> <a href=\"?m:TokenType.String!\">String</a></h2>\n<code>func (t TokenType) String() string</code>\n<p>\nString returns a string representation of the TokenType.\n</p>\n\n",name:"String"}]},{html:"\n<h2><a class=\"black\" href=\"?t:\">type</a> <a href=\"?t:Tokenizer!\">Tokenizer</a></h2>\n<pre>type Tokenizer struct {\n\t// If ReturnComments is set, Next returns comment tokens;\n\t// otherwise it skips over comments (default).\n\tReturnComments bool\n\t// contains unexported fields\n}</pre>\n<p>\nA Tokenizer returns a stream of HTML Tokens.\n</p>\n\n",name:"Tokenizer","methods":[{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.Error!\">Error</a></h2>\n<code>func (z *Tokenizer) Error() os.Error</code>\n<p>\nError returns the error associated with the most recent ErrorToken token.\nThis is typically os.EOF, meaning the end of tokenization.\n</p>\n\n",name:"Error"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.Next!\">Next</a></h2>\n<code>func (z *Tokenizer) Next() TokenType</code>\n<p>\nNext scans the next token and returns its type.\n</p>\n\n",name:"Next"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.Raw!\">Raw</a></h2>\n<code>func (z *Tokenizer) Raw() []byte</code>\n<p>\nRaw returns the unmodified text of the current token. Calling Next, Token,\nText, TagName or TagAttr may change the contents of the returned slice.\n</p>\n\n",name:"Raw"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.TagAttr!\">TagAttr</a></h2>\n<code>func (z *Tokenizer) TagAttr() (key, val []byte, moreAttr bool)</code>\n<p>\nTagAttr returns the lower-cased key and unescaped value of the next unparsed\nattribute for the current tag token and whether there are more attributes.\nThe contents of the returned slices may change on the next call to Next.\n</p>\n\n",name:"TagAttr"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.TagName!\">TagName</a></h2>\n<code>func (z *Tokenizer) TagName() (name []byte, hasAttr bool)</code>\n<p>\nTagName returns the lower-cased name of a tag token (the `img` out of\n`&lt;IMG SRC=&#34;foo&#34;&gt;`) and whether the tag has attributes.\nThe contents of the returned slice may change on the next call to Next.\n</p>\n\n",name:"TagName"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.Text!\">Text</a></h2>\n<code>func (z *Tokenizer) Text() []byte</code>\n<p>\nText returns the unescaped text of a TextToken or a CommentToken.\nThe contents of the returned slice may change on the next call to Next.\n</p>\n\n",name:"Text"},{html:"\n<h2><a class=\"black\" href=\"?m:Tokenizer\">func (*Tokenizer)</a> <a href=\"?m:Tokenizer.Token!\">Token</a></h2>\n<code>func (z *Tokenizer) Token() Token</code>\n<p>\nToken returns the next Token. The result&#39;s Data and Attr values remain valid\nafter subsequent Next calls.\n</p>\n\n",name:"Token"}]}],funcs:[{html:"\n<h2><a class=\"black\" href=\"?f:\">func</a> <a href=\"?f:EscapeString!\">EscapeString</a></h2>\n<code>func EscapeString(s string) string</code>\n<p>\nEscapeString escapes special characters like &#34;&lt;&#34; to become &#34;&amp;lt;&#34;. It\nescapes only five such characters: amp, apos, lt, gt and quot.\nUnescapeString(EscapeString(s)) == s always holds, but the converse isn&#39;t\nalways true.\n</p>\n\n",name:"EscapeString"},{html:"\n<h2><a class=\"black\" href=\"?f:\">func</a> <a href=\"?f:NewTokenizer!\">NewTokenizer</a></h2>\n<code>func NewTokenizer(r io.Reader) *Tokenizer</code>\n<p>\nNewTokenizer returns a new HTML Tokenizer for the given Reader.\nThe input is assumed to be UTF-8 encoded.\n</p>\n\n",name:"NewTokenizer"},{html:"\n<h2><a class=\"black\" href=\"?f:\">func</a> <a href=\"?f:Parse!\">Parse</a></h2>\n<code>func Parse(r io.Reader) (*Node, os.Error)</code>\n<p>\nParse returns the parse tree for the HTML from the given Reader.\nThe input is assumed to be UTF-8 encoded.\n</p>\n\n",name:"Parse"},{html:"\n<h2><a class=\"black\" href=\"?f:\">func</a> <a href=\"?f:UnescapeString!\">UnescapeString</a></h2>\n<code>func UnescapeString(s string) string</code>\n<p>\nUnescapeString unescapes entities like &#34;&amp;lt;&#34; to become &#34;&lt;&#34;. It unescapes a\nlarger range of entities than EscapeString escapes. For example, &#34;&amp;aacute;&#34;\nunescapes to &#34;\u  &#34;, as does &#34;&amp;#225;&#34; and &#34;&amp;xE1;&#34;.\nUnescapeString(EscapeString(s)) == s always holds, but the converse isn&#39;t\nalways true.\n</p>\n\n",name:"UnescapeString"}],consts:[{html:"\n<h2><a class=\"black\" href=\"?c:\">const</a> <a href=\"?c:TokenType!\">TokenType</a></h2>\n<pre>const (\n\t// ErrorToken means that an error occurred during tokenization.\n\tErrorToken TokenType = iota\n\t// TextToken means a text node.\n\tTextToken\n\t// A StartTagToken looks like &lt;a&gt;.\n\tStartTagToken\n\t// An EndTagToken looks like &lt;/a&gt;.\n\tEndTagToken\n\t// A SelfClosingTagToken tag looks like &lt;br/&gt;.\n\tSelfClosingTagToken\n\t// A CommentToken looks like &lt;!--x--&gt;.\n\tCommentToken\n)</pre>\n\n",names:["ErrorToken","TextToken","StartTagToken","EndTagToken","SelfClosingTagToken","CommentToken"],type:"TokenType"},{html:"\n<h2><a class=\"black\" href=\"?c:\">const</a> <a href=\"?c:NodeType!\">NodeType</a></h2>\n<pre>const (\n\tErrorNode NodeType = iota\n\tTextNode\n\tDocumentNode\n\tElementNode\n\tCommentNode\n)</pre>\n\n",names:["ErrorNode","TextNode","DocumentNode","ElementNode","CommentNode"],type:"NodeType"}],vars:[]}